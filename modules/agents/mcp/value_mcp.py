"""å€¼çº¦æŸMCP - éªŒè¯å’Œä¿®å¤å€¼èŒƒå›´ã€åŸŸçº¦æŸç­‰é—®é¢˜"""
import re
from typing import List, Dict, Any, Optional
from .base import MCPVerifier, MCPFixer, BaseMCP, get_table_definition, get_cell_value, is_valid_fix_value
from ...memory import TableSnapshot, Violation, Fix, SuggestedFix, ConstraintType, ViolationSeverity, FixType
from ...core.ids import IdGenerator


class ValueVerifier(MCPVerifier):
    """å€¼çº¦æŸéªŒè¯å™¨"""
    
    def __init__(self):
        super().__init__("ValueVerifier.v1")
    
    def get_supported_constraints(self) -> List[str]:
        return [
            ConstraintType.VALUE.value,
        ]
    
    def can_handle(self, constraint_type: str) -> bool:
        return constraint_type in self.get_supported_constraints()
    
    def verify(self, snapshot: TableSnapshot, schema: Dict[str, Any], 
               table_name: str, context=None) -> List[Violation]:
        """éªŒè¯è¡¨æ ¼ä¸­çš„å€¼çº¦æŸ"""
        violations = []
        table_def = get_table_definition(schema, table_name)
        
        if not table_def:
            return violations
        
        attributes = table_def.get('attributes', [])
        attr_dict = {attr['name']: attr for attr in attributes}
        
        for row in snapshot.rows:
            for attr_name, cell_data in row.cells.items():
                if attr_name not in attr_dict:
                    continue
                
                attr_def = attr_dict[attr_name]
                value = cell_data.value
                
                cell_violations = self.verify_cell(
                    snapshot.table, row.tuple_id, attr_name, 
                    value, attr_def, snapshot, context
                )
                violations.extend(cell_violations)
        
        if context and hasattr(context, 'all_snapshots'):
            cross_table_violations = self._check_cross_table_entity_consistency(
                table_name, snapshot, context.all_snapshots, schema
            )
            violations.extend(cross_table_violations)
        
        return violations
    
    def verify_cell(self, table: str, tuple_id: str, attr: str, 
                   value: Any, attr_def: Dict[str, Any], 
                   snapshot: TableSnapshot, context=None) -> List[Violation]:
        """éªŒè¯å•ä¸ªå•å…ƒæ ¼çš„å€¼çº¦æŸ"""
        violations = []
        
        if value is None or str(value).strip() == '' or str(value).lower() == 'null':
            constraints = attr_def.get('constraints', [])
            has_not_null_constraint = (
                'NOT NULL' in constraints or
                (isinstance(constraints, dict) and constraints.get('nullable') == False)
            )
            
            attr_type = attr_def.get('type', '').upper()
            is_numeric_type = any(t in attr_type for t in ['DECIMAL', 'INTEGER', 'FLOAT', 'DOUBLE', 'NUMBER', 'INT'])
            
            has_non_null_in_other_rows = self._check_field_has_values_in_snapshot(
                snapshot, attr, table, tuple_id
            )
            
            if has_not_null_constraint or (is_numeric_type and has_non_null_in_other_rows):
                violation_id = IdGenerator.generate_violation_id(
                    table, tuple_id, attr, ConstraintType.VALUE.value
                )
                
                suggested_value = self._suggest_null_fix(attr, attr_def)
                
                if has_not_null_constraint:
                    description = f"å­—æ®µ {attr} ç¼ºå¤±å€¼ï¼ˆç©ºå€¼/nullï¼‰ï¼Œè¿åäº†NOT NULLçº¦æŸ"
                    severity = ViolationSeverity.ERROR.value
                else:
                    description = f"å­—æ®µ {attr} ç¼ºå¤±å€¼ï¼ˆç©ºå€¼/nullï¼‰ï¼Œå»ºè®®ä»æ–‡æ¡£ä¸­é‡æ–°æå–è¡¥å……è¯¥å€¼"
                    severity = ViolationSeverity.ERROR.value  # æ”¹ä¸ºERRORä»¥è§¦å‘warm start
                
                violation = Violation(
                    id=violation_id,
                    table=table,
                    tuple_id=tuple_id,
                    attr=attr,
                    constraint_type=ConstraintType.VALUE.value,
                    description=description,
                    severity=severity,
                    suggested_fix=SuggestedFix(value=suggested_value),
                    detector_id=self.mcp_id,
                    timestamp=""
                )
                violations.append(violation)
            return violations
        
        range_violations = self._check_range_constraint(
            table, tuple_id, attr, value, attr_def
        )
        violations.extend(range_violations)
        
        domain_violations = self._check_domain_constraint(
            table, tuple_id, attr, value, attr_def
        )
        violations.extend(domain_violations)
        
        enum_violations = self._check_enum_constraint(
            table, tuple_id, attr, value, attr_def
        )
        violations.extend(enum_violations)
        
        return violations
    
    def _check_range_constraint(self, table: str, tuple_id: str, attr: str, 
                               value: Any, attr_def: Dict[str, Any]) -> List[Violation]:
        """æ£€æŸ¥èŒƒå›´çº¦æŸ"""
        violations = []
        min_val = attr_def.get('min')
        max_val = attr_def.get('max')
        
        constraints = attr_def.get('constraints', [])
        for constraint in constraints:
            if isinstance(constraint, str):
                if 'CHECK >=' in constraint:
                    try:
                        min_val = float(constraint.split('>=')[1].strip())
                    except (ValueError, IndexError):
                        pass
                elif 'CHECK <=' in constraint:
                    try:
                        max_val = float(constraint.split('<=')[1].strip())
                    except (ValueError, IndexError):
                        pass
                elif 'CHECK >' in constraint:
                    try:
                        min_val = float(constraint.split('>')[1].strip()) + 0.001
                    except (ValueError, IndexError):
                        pass
                elif 'CHECK <' in constraint:
                    try:
                        max_val = float(constraint.split('<')[1].strip()) - 0.001
                    except (ValueError, IndexError):
                        pass
        
        if (min_val is not None or max_val is not None) and value is not None:
            try:
                numeric_value = self._extract_numeric_value(str(value))
                
                if min_val is not None and numeric_value < min_val:
                    violation_id = IdGenerator.generate_violation_id(
                        table, tuple_id, attr, ConstraintType.VALUE.value
                    )
                    
                    violation = Violation(
                        id=violation_id,
                        table=table,
                        tuple_id=tuple_id,
                        attr=attr,
                        constraint_type=ConstraintType.VALUE.value,
                        description=f"å­—æ®µ {attr} å€¼ {value} å°äºæœ€å°å€¼ {min_val}",
                        severity=ViolationSeverity.WARN.value,
                        suggested_fix=SuggestedFix(value=str(min_val)),
                        detector_id=self.mcp_id,
                        timestamp=""
                    )
                    violations.append(violation)
                
                elif max_val is not None and numeric_value > max_val:
                    violation_id = IdGenerator.generate_violation_id(
                        table, tuple_id, attr, ConstraintType.VALUE.value
                    )
                    
                    violation = Violation(
                        id=violation_id,
                        table=table,
                        tuple_id=tuple_id,
                        attr=attr,
                        constraint_type=ConstraintType.VALUE.value,
                        description=f"å­—æ®µ {attr} å€¼ {value} å¤§äºæœ€å¤§å€¼ {max_val}",
                        severity=ViolationSeverity.WARN.value,
                        suggested_fix=SuggestedFix(value=str(max_val)),
                        detector_id=self.mcp_id,
                        timestamp=""
                    )
                    violations.append(violation)
                    
            except ValueError:
                pass
        
        return violations
    
    def _check_domain_constraint(self, table: str, tuple_id: str, attr: str, 
                                value: Any, attr_def: Dict[str, Any]) -> List[Violation]:
        """æ£€æŸ¥åŸŸçº¦æŸ"""
        violations = []
        domain = attr_def.get('domain')
        
        constraints = attr_def.get('constraints', [])
        for constraint in constraints:
            if isinstance(constraint, str) and 'CHECK IN' in constraint:
                try:
                    in_part = constraint.split('CHECK IN')[1].strip()
                    if in_part.startswith('(') and in_part.endswith(')'):
                        values_str = in_part[1:-1]  # ç§»é™¤æ‹¬å·
                        domain = [val.strip().strip("'\"") for val in values_str.split(',')]
                except (IndexError, ValueError):
                    pass
        
        if domain and value is not None and str(value).strip():
            str_value = str(value).strip()
            if str_value not in domain:
                violation_id = IdGenerator.generate_violation_id(
                    table, tuple_id, attr, ConstraintType.VALUE.value
                )
                
                suggested_value = self._find_closest_domain_value(str_value, domain)
                
                violation = Violation(
                    id=violation_id,
                    table=table,
                    tuple_id=tuple_id,
                    attr=attr,
                    constraint_type=ConstraintType.VALUE.value,
                    description=f"å­—æ®µ {attr} å€¼ '{value}' ä¸åœ¨å…è®¸çš„åŸŸ {domain} ä¸­",
                    severity=ViolationSeverity.WARN.value,
                    suggested_fix=SuggestedFix(value=suggested_value),
                    detector_id=self.mcp_id,
                    timestamp=""
                )
                violations.append(violation)
        
        return violations
    
    def _check_enum_constraint(self, table: str, tuple_id: str, attr: str, 
                              value: Any, attr_def: Dict[str, Any]) -> List[Violation]:
        """æ£€æŸ¥æšä¸¾å€¼çº¦æŸ"""
        violations = []
        enum_values = attr_def.get('enum')
        
        if enum_values and value is not None and str(value).strip():
            str_value = str(value).strip()
            if str_value not in enum_values:
                violation_id = IdGenerator.generate_violation_id(
                    table, tuple_id, attr, ConstraintType.VALUE.value
                )
                
                suggested_value = self._find_closest_domain_value(str_value, enum_values)
                
                violation = Violation(
                    id=violation_id,
                    table=table,
                    tuple_id=tuple_id,
                    attr=attr,
                    constraint_type=ConstraintType.VALUE.value,
                    description=f"å­—æ®µ {attr} å€¼ '{value}' ä¸åœ¨å…è®¸çš„æšä¸¾å€¼ {enum_values} ä¸­",
                    severity=ViolationSeverity.WARN.value,
                    
                    suggested_fix=SuggestedFix(value=suggested_value, ),
                    detector_id=self.mcp_id,
                    timestamp=""
                )
                violations.append(violation)
        
        return violations
    
    def _extract_numeric_value(self, value: str) -> float:
        """ä»å­—ç¬¦ä¸²ä¸­æå–æ•°å€¼"""
        cleaned = re.sub(r'[,Â¥$â‚¬Â£\s]', '', value.strip())
        return float(cleaned)
    
    def _find_closest_domain_value(self, value: str, domain: List[str]) -> str:
        """æ‰¾åˆ°æœ€æ¥è¿‘çš„åŸŸå€¼"""
        if not domain:
            return value
        
        for domain_val in domain:
            if value.lower() == domain_val.lower():
                return domain_val
        
        best_match = domain[0]
        best_score = 0
        
        for domain_val in domain:
            value_chars = set(value.lower())
            domain_chars = set(domain_val.lower())
            intersection = len(value_chars & domain_chars)
            union = len(value_chars | domain_chars)
            
            if union > 0:
                score = intersection / union
                if score > best_score:
                    best_score = score
                    best_match = domain_val
        
        return best_match
    
    def _check_field_has_values_in_snapshot(self, snapshot: TableSnapshot, 
                                            attr: str, table: str, 
                                            current_tuple_id: str) -> bool:
        """
        æ£€æŸ¥å¿«ç…§ä¸­å…¶ä»–è®°å½•æ˜¯å¦æœ‰è¯¥å­—æ®µçš„énullå€¼
        å¦‚æœæœ‰ï¼Œè¯´æ˜è¿™ä¸ªå­—æ®µé€šå¸¸åº”è¯¥æœ‰å€¼ï¼Œå½“å‰è®°å½•çš„nullå¯èƒ½æ˜¯é—æ¼
        """
        if not snapshot or not snapshot.rows:
            return False
        
        for row in snapshot.rows:
            if row.tuple_id == current_tuple_id:
                continue
            
            if attr in row.cells:
                cell_value = row.cells[attr].value
                if cell_value is not None and str(cell_value).strip() != '' and str(cell_value).lower() != 'null':
                    return True
        
        return False
    
    def _check_cross_table_entity_consistency(self, current_table: str, 
                                             current_snapshot: TableSnapshot,
                                             all_snapshots: Dict[str, TableSnapshot],
                                             schema: Dict[str, Any]) -> List[Violation]:
        """æ£€æµ‹è·¨è¡¨ç›¸ä¼¼å®ä½“è¡¨ç¤ºä¸ä¸€è‡´
        
        ä¾‹å¦‚ï¼šä¸€ä¸ªè¡¨ä¸­æ˜¯"æ ¼åŠ›ç”µå™¨"ï¼Œå¦ä¸€ä¸ªè¡¨ä¸­æ˜¯"æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸"
        
        Args:
            current_table: å½“å‰è¡¨å
            current_snapshot: å½“å‰è¡¨çš„å¿«ç…§
            all_snapshots: æ‰€æœ‰è¡¨çš„å¿«ç…§å­—å…¸
            schema: æ•°æ®åº“schema
            
        Returns:
            è·¨è¡¨å®ä½“ä¸ä¸€è‡´çš„è¿è§„åˆ—è¡¨
        """
        violations = []
        
        if len(all_snapshots) < 2:
            return violations
        
        if not current_snapshot.rows:
            return violations
        
        current_fields = set(current_snapshot.rows[0].cells.keys())
        
        for other_table_name, other_snapshot in all_snapshots.items():
            if other_table_name == current_table:
                continue
            
            if not other_snapshot.rows:
                continue
            
            other_fields = set(other_snapshot.rows[0].cells.keys())
            common_fields = current_fields & other_fields
            
            for field_name in common_fields:
                field_violations = self._check_field_entity_consistency(
                    current_table, current_snapshot,
                    other_table_name, other_snapshot,
                    field_name
                )
                violations.extend(field_violations)
        
        return violations
    
    def _check_field_entity_consistency(self, table1: str, snapshot1: TableSnapshot,
                                       table2: str, snapshot2: TableSnapshot,
                                       field_name: str) -> List[Violation]:
        """æ£€æŸ¥ç‰¹å®šå­—æ®µåœ¨ä¸¤ä¸ªè¡¨ä¹‹é—´çš„å®ä½“ä¸€è‡´æ€§"""
        violations = []
        
        values1 = set()
        for row in snapshot1.rows:
            if field_name in row.cells:
                val = row.cells[field_name].value
                if val is not None and str(val).strip():
                    values1.add(str(val).strip())
        
        values2 = set()
        for row in snapshot2.rows:
            if field_name in row.cells:
                val = row.cells[field_name].value
                if val is not None and str(val).strip():
                    values2.add(str(val).strip())
        
        if not values1 or not values2:
            return violations
        
        similar_groups = self._detect_similar_entity_groups(values1, values2)
        
        if not similar_groups:
            return violations
        
        self.logger.info(f"  ğŸ” å­—æ®µ '{field_name}' åœ¨è¡¨ {table1} å’Œ {table2} é—´å‘ç° {len(similar_groups)} ç»„ç›¸ä¼¼å®ä½“")
        
        for similar_group in similar_groups:
            canonical_form = max(similar_group, key=len)
            
            for form in similar_group:
                if form != canonical_form and form in values1:
                    violations.extend(self._generate_entity_violations(
                        table1, snapshot1, field_name, form, canonical_form, similar_group
                    ))
            
            self.logger.info(f"    ç›¸ä¼¼å®ä½“ç»„: {similar_group}")
            self.logger.info(f"    æ ‡å‡†å½¢å¼: {canonical_form}")
        
        return violations
    
    def _generate_entity_violations(self, table: str, snapshot: TableSnapshot,
                                   field_name: str, current_form: str,
                                   canonical_form: str, similar_group: set) -> List[Violation]:
        """ä¸ºä½¿ç”¨éæ ‡å‡†å½¢å¼çš„è®°å½•ç”Ÿæˆè¿è§„"""
        violations = []
        
        for row in snapshot.rows:
            if field_name not in row.cells:
                continue
            
            cell_value = row.cells[field_name].value
            if cell_value is not None and str(cell_value).strip() == current_form:
                violation_id = IdGenerator.generate_violation_id(
                    table, row.tuple_id, field_name, ConstraintType.VALUE.value
                )
                
                description = (
                    f"è·¨è¡¨å®ä½“è¡¨ç¤ºä¸ä¸€è‡´: å­—æ®µ '{field_name}' çš„å€¼ '{current_form}' "
                    f"ä¸å…¶ä»–è¡¨ä¸­çš„ç›¸ä¼¼å®ä½“ {similar_group} è¡¨ç¤ºä¸ç»Ÿä¸€ï¼Œå»ºè®®ç»Ÿä¸€ä¸º '{canonical_form}'"
                )
                
                violation = Violation(
                    id=violation_id,
                    table=table,
                    tuple_id=row.tuple_id,
                    attr=field_name,
                    constraint_type=ConstraintType.VALUE.value,
                    description=description,
                    severity=ViolationSeverity.WARN.value,
                    suggested_fix=SuggestedFix(value=canonical_form),
                    detector_id=self.mcp_id,
                    timestamp=""
                )
                violations.append(violation)
        
        return violations
    
    def _detect_similar_entity_groups(self, values1: set, values2: set) -> List[set]:
        """æ£€æµ‹ä¸¤ä¸ªå€¼é›†åˆä¸­çš„ç›¸ä¼¼å®ä½“ç»„
        
        Returns:
            ç›¸ä¼¼å®ä½“ç»„åˆ—è¡¨ï¼Œæ¯ç»„åŒ…å«è·¨è¡¨çš„ç›¸ä¼¼å€¼
        """
        similar_groups = []
        all_values = values1 | values2
        grouped_values = set()
        
        for val1 in all_values:
            if val1 in grouped_values:
                continue
            
            similar_group = {val1}
            grouped_values.add(val1)
            
            for val2 in all_values:
                if val2 == val1 or val2 in grouped_values:
                    continue
                
                if self._are_values_similar(val1, val2):
                    similar_group.add(val2)
                    grouped_values.add(val2)
            
            if len(similar_group) > 1:
                has_from_table1 = any(v in values1 for v in similar_group)
                has_from_table2 = any(v in values2 for v in similar_group)
                
                if has_from_table1 and has_from_table2:
                    similar_groups.append(similar_group)
        
        return similar_groups
    
    def _are_values_similar(self, val1: str, val2: str) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªå€¼æ˜¯å¦ç›¸ä¼¼ï¼ˆå¯èƒ½æŒ‡ä»£åŒä¸€å®ä½“ï¼‰
        
        ä½¿ç”¨å¤šç§å¯å‘å¼è§„åˆ™åˆ¤æ–­ï¼š
        1. å­ä¸²å…³ç³»ï¼šä¸€ä¸ªæ˜¯å¦ä¸€ä¸ªçš„å­ä¸²ï¼ˆå¦‚"æ ¼åŠ›ç”µå™¨" vs "æ ¼åŠ›ç”µå™¨è‚¡ä»½æœ‰é™å…¬å¸"ï¼‰
        2. å…¬å¸/æœºæ„åç§°ç‰¹å¾ï¼šå»é™¤åç¼€è¯åç›¸åŒ
        3. ç¼–è¾‘è·ç¦»ï¼šLevenshteinè·ç¦»è¾ƒå°
        """
        if not val1 or not val2:
            return False
        
        val1_str = str(val1).strip()
        val2_str = str(val2).strip()
        
        if val1_str == val2_str:
            return False  # ä¸ç®—ç›¸ä¼¼å®ä½“ï¼Œç®—å®Œå…¨ä¸€è‡´
        
        if val1_str in val2_str or val2_str in val1_str:
            min_len = min(len(val1_str), len(val2_str))
            if min_len >= 3:  # è‡³å°‘3ä¸ªå­—ç¬¦
                return True
        
        entity_suffixes = [
            "è‚¡ä»½æœ‰é™å…¬å¸", "æœ‰é™å…¬å¸", "é›†å›¢", "è‚¡ä»½å…¬å¸", 
            "å…¬å¸", "é›†å›¢è‚¡ä»½æœ‰é™å…¬å¸", "ï¼ˆé›†å›¢ï¼‰è‚¡ä»½æœ‰é™å…¬å¸",
            "Co.,Ltd", "Inc.", "Corp.", "Ltd.",
            "å¤§å­¦", "å­¦é™¢", "ç ”ç©¶æ‰€", "ç ”ç©¶é™¢", "ä¸­å¿ƒ"
        ]
        
        val1_core = val1_str
        val2_core = val2_str
        
        for suffix in entity_suffixes:
            val1_core = val1_core.replace(suffix, "")
            val2_core = val2_core.replace(suffix, "")
        
        val1_core = val1_core.strip()
        val2_core = val2_core.strip()
        
        if val1_core and val2_core:
            if val1_core == val2_core:
                return True
            
            if val1_core in val2_core or val2_core in val1_core:
                min_len = min(len(val1_core), len(val2_core))
                if min_len >= 2:
                    return True
        
        max_len = max(len(val1_str), len(val2_str))
        min_len = min(len(val1_str), len(val2_str))
        
        if max_len > 0:
            edit_distance = self._levenshtein_distance(val1_str, val2_str)
            similarity_ratio = 1 - (edit_distance / max_len)
            
            if similarity_ratio > 0.9 and min_len >= 5:
                return True
        
        return False
    
    def _levenshtein_distance(self, s1: str, s2: str) -> int:
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„Levenshteinç¼–è¾‘è·ç¦»"""
        if len(s1) < len(s2):
            return self._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    def _suggest_null_fix(self, attr: str, attr_def: Dict[str, Any]) -> str:
        """ä¸ºNULLå€¼ç”Ÿæˆå»ºè®®ä¿®å¤å€¼"""
        attr_type = attr_def.get('type', '').lower()
        
        if 'id' in attr.lower():
            return "1"
        elif 'name' in attr.lower() or 'varchar' in attr_type or 'text' in attr_type:
            return "æœªçŸ¥"
        elif 'date' in attr_type:
            return "2024-01-01"
        elif 'decimal' in attr_type or 'float' in attr_type or 'number' in attr_type:
            return "0"
        elif 'status' in attr.lower():
            constraints = attr_def.get('constraints', [])
            for constraint in constraints:
                if isinstance(constraint, str) and 'CHECK IN' in constraint:
                    try:
                        in_part = constraint.split('CHECK IN')[1].strip()
                        if in_part.startswith('(') and in_part.endswith(')'):
                            values_str = in_part[1:-1]
                            values = [val.strip().strip("'\"") for val in values_str.split(',')]
                            if values:
                                return values[0]  # è¿”å›ç¬¬ä¸€ä¸ªåˆæ³•å€¼
                    except (IndexError, ValueError):
                        pass
            return "å¾…ç¡®è®¤"
        else:
            return "å¾…è¡¥å……"


class ValueFixer(MCPFixer):
    """å€¼çº¦æŸä¿®å¤å™¨"""
    
    def __init__(self):
        super().__init__("ValueFixer.v1")
    
    def get_supported_constraints(self) -> List[str]:
        return [
            ConstraintType.VALUE.value,
        ]
    
    def can_handle(self, constraint_type: str) -> bool:
        return constraint_type in self.get_supported_constraints()
    
    def can_fix(self, violation: Violation) -> bool:
        if violation.constraint_type not in self.get_supported_constraints():
            return False
        
        description = violation.description.lower() if violation.description else ""
        if any(keyword in description for keyword in ['ç¼ºå¤±å€¼', 'missing', 'ç©ºå€¼', 'null']):
            return False
        
        return True
    
    def get_supported_fix_types(self) -> List[str]:
        return [
            FixType.RANGE_CLAMP.value,
            FixType.DOMAIN_MAPPING.value,
            FixType.VALUE_CORRECTION.value
        ]
    
    def fix(self, violation: Violation, snapshot: TableSnapshot, 
            context=None) -> List[Fix]:
        """ä¿®å¤å€¼çº¦æŸè¿è§„"""
        if not self.can_fix(violation):
            return []
        
        fixes = []
        old_value = get_cell_value(violation, snapshot)
        
        if not violation.suggested_fix or not violation.suggested_fix.value:
            return fixes
        
        if violation.suggested_fix and violation.suggested_fix.value:
            suggested_value = violation.suggested_fix.value
            if is_valid_fix_value(suggested_value):
                new_value = suggested_value
            else:
                self.logger.warning(f"å»ºè®®ä¿®å¤å€¼'{suggested_value}'çœ‹èµ·æ¥æ˜¯æç¤ºæ–‡æœ¬è€Œéæ•°æ®å€¼ï¼Œè·³è¿‡ä¿®å¤")
                return fixes
            
            fix_type = self._determine_fix_type(violation.constraint_type)
            
            fix_id = IdGenerator.generate_fix_id(
                violation.table, violation.tuple_id, violation.attr,
                fix_type, old_value
            )
            
            old_value_str = old_value if old_value is not None else ""
            
            fix = Fix(
                id=fix_id,
                table=violation.table,
                tuple_id=violation.tuple_id,
                attr=violation.attr,
                old=old_value_str,
                new=new_value,
                fix_type=fix_type,
                applied_by=self.mcp_id,
                timestamp=""
            )
            fixes.append(fix)
        
        return fixes
    
    def _determine_fix_type(self, constraint_type: str) -> str:
        """ç¡®å®šä¿®å¤ç±»å‹"""
        if constraint_type == ConstraintType.VALUE.value:
            return FixType.DOMAIN_MAPPING.value
        else:
            return FixType.VALUE_CORRECTION.value
    
    def fix_batch(self, violations: List[Violation], snapshot: TableSnapshot, 
                  context=None) -> List[Fix]:
        """
        æ‰¹é‡ä¿®å¤å€¼çº¦æŸè¿è§„
        
        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. å¯¹äºæœ‰ suggested_fix çš„è¿è§„ï¼Œç›´æ¥åº”ç”¨ä¿®å¤ï¼ˆä¸éœ€è¦LLMï¼‰
        2. å¯¹äºæ²¡æœ‰ suggested_fix çš„è¿è§„ï¼Œä½¿ç”¨ LLM æ‰¹é‡æ¨æ–­ä¿®å¤å€¼
        """
        all_fixes = []
        
        with_suggestion = []
        need_llm = []
        
        for violation in violations:
            if not self.can_fix(violation):
                continue
                
            if violation.suggested_fix and violation.suggested_fix.value:
                with_suggestion.append(violation)
            else:
                need_llm.append(violation)
        
        for violation in with_suggestion:
            fixes = self.fix(violation, snapshot, context)
            all_fixes.extend(fixes)
        
        if need_llm:
            llm_fixes = self._batch_fix_with_llm(need_llm, snapshot, context)
            all_fixes.extend(llm_fixes)
        
        if all_fixes:
            self.logger.info(f"ValueFixer: æ‰¹é‡ä¿®å¤ {len(violations)} ä¸ªè¿è§„ï¼Œç”Ÿæˆ {len(all_fixes)} ä¸ªä¿®å¤")
        
        return all_fixes
    
    def _batch_fix_with_llm(self, violations: List[Violation], 
                           snapshot: TableSnapshot, context=None) -> List[Fix]:
        """ä½¿ç”¨LLMæ‰¹é‡æ¨æ–­ä¿®å¤å€¼"""
        fixes = []
        
        try:
            from llm.main import get_answer
            import json
            
            violations_info = []
            for i, v in enumerate(violations):
                old_value = get_cell_value(v, snapshot)
                violations_info.append({
                    "index": i,
                    "tuple_id": v.tuple_id,
                    "attr": v.attr,
                    "current_value": old_value,
                    "description": v.description,
                    "constraint_type": v.constraint_type
                })
            
            table_context = self._build_table_context(snapshot, violations)
            
            system_prompt = """You are a data quality expert. Your task is to suggest corrected values for data quality violations.
Output in strict JSON format: {"fixes": [{"index": 0, "new_value": "corrected value"}, ...]}
Use null if the value cannot be determined."""
            
            user_prompt = f"""Please suggest corrections for the following value violations:

Table: {snapshot.table}
Violations to fix:
{json.dumps(violations_info, ensure_ascii=False, indent=2)}

Table Context (sample rows):
{table_context}

Requirements:
- For domain violations: map to the correct domain value
- For range violations: adjust to within the valid range
- For missing values: suggest a reasonable default or null
- Output ONLY JSON in format: {{"fixes": [{{"index": 0, "new_value": "..."}}]}}
"""
            
            model = context.model if context and hasattr(context, 'model') else "gpt-4o"
            llm_response = get_answer(user_prompt, system_prompt=system_prompt, model=model)
            
            fixes_data = self._parse_llm_fixes(llm_response)
            
            for fix_data in fixes_data:
                idx = fix_data.get('index')
                new_value = fix_data.get('new_value')
                
                if idx is None or idx >= len(violations):
                    continue
                
                violation = violations[idx]
                old_value = get_cell_value(violation, snapshot)
                
                if new_value is None or str(new_value).lower() == 'null':
                    continue
                
                if not is_valid_fix_value(str(new_value)):
                    self.logger.warning(f"å»ºè®®ä¿®å¤å€¼'{new_value}'çœ‹èµ·æ¥æ˜¯æç¤ºæ–‡æœ¬ï¼Œè·³è¿‡")
                    continue
                
                fix_type = self._determine_fix_type(violation.constraint_type)
                fix_id = IdGenerator.generate_fix_id(
                    violation.table, violation.tuple_id, violation.attr,
                    fix_type, old_value
                )
                
                fix = Fix(
                    id=fix_id,
                    table=violation.table,
                    tuple_id=violation.tuple_id,
                    attr=violation.attr,
                    old=old_value if old_value is not None else "",
                    new=str(new_value),
                    fix_type=fix_type,
                    applied_by=self.mcp_id,
                    timestamp=""
                )
                fixes.append(fix)
            
        except Exception as e:
            self.logger.error(f"LLMæ‰¹é‡ä¿®å¤å¤±è´¥: {e}")
            for violation in violations:
                try:
                    individual_fixes = self.fix(violation, snapshot, context)
                    fixes.extend(individual_fixes)
                except Exception as fix_error:
                    self.logger.error(f"ä¿®å¤è¿è§„ {violation.id} å¤±è´¥: {fix_error}")
        
        return fixes
    
    def _build_table_context(self, snapshot: TableSnapshot, 
                            violations: List[Violation]) -> str:
        """æ„å»ºè¡¨æ ¼ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        lines = []
        
        for i, row in enumerate(snapshot.rows[:5]):
            row_data = {attr: cell.value for attr, cell in row.cells.items()}
            lines.append(f"Row {i+1} (tuple_id={row.tuple_id}): {row_data}")
        
        if len(snapshot.rows) > 5:
            lines.append(f"... ({len(snapshot.rows)} rows total)")
        
        return "\n".join(lines)
    
    def _parse_llm_fixes(self, llm_response: str) -> List[Dict[str, Any]]:
        """è§£æLLMè¿”å›çš„ä¿®å¤æ•°æ®"""
        import json
        import re
        
        json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', llm_response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_str = llm_response.strip()
        
        try:
            data = json.loads(json_str)
            
            if isinstance(data, dict) and 'fixes' in data:
                return data['fixes']
            elif isinstance(data, list):
                return data
            else:
                return []
                
        except json.JSONDecodeError as e:
            self.logger.error(f"JSONè§£æå¤±è´¥: {e}")
            return []


class ValueMCP(BaseMCP):
    """å€¼çº¦æŸMCP"""
    
    def __init__(self):
        verifier = ValueVerifier()
        fixer = ValueFixer()
        super().__init__("ValueMCP.v1", verifier, fixer)
